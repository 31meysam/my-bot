from aiogram import Bot, Dispatcher, executor  # Ø®Ø· Û±
from aiogram import types  # Ø®Ø· Û²
import openai
import os
from dotenv import load_dotenv
# Ø¨Ù‚ÛŒÙ‡ Ú©Ø¯Ù‡Ø§ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±..
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
load_dotenv()
TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")

bot = Bot(token=TOKEN)
dp = Dispatcher(bot)
openai.api_key = OPENAI_KEY

# Ø¯Ø³ØªÙˆØ±Ø§Øª Ø±Ø¨Ø§Øª
@dp.message_handler(commands=['start', 'help'])
async def send_welcome(message: types.Message):
    await message.reply("""
    ğŸ¤– Ø±Ø¨Ø§Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ¹Ø§Ù„ Ø´Ø¯!
    /gpt <Ù¾ÛŒØ§Ù…> - Ú†Øª Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
    /img <ØªÙˆØ¶ÛŒØ­> - ØªÙˆÙ„ÛŒØ¯ Ø¹Ú©Ø³
    """)

# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ
@dp.message_handler(commands=['gpt'])
async def chat_gpt(message: types.Message):
    prompt = message.get_args()
    if not prompt:
        await message.reply("Ù„Ø·ÙØ§Ù‹ Ù¾Ø³ Ø§Ø² /gpt Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯")
        return
    
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        await message.reply(response.choices[0].message['content'])
    except Exception as e:
        await message.reply(f"Ø®Ø·Ø§: {str(e)}")

# ØªÙˆÙ„ÛŒØ¯ Ø¹Ú©Ø³
@dp.message_handler(commands=['img'])
async def generate_image(message: types.Message):
    prompt = message.get_args()
    if not prompt:
        await message.reply("Ù„Ø·ÙØ§Ù‹ Ù¾Ø³ Ø§Ø² /img ØªÙˆØ¶ÛŒØ­ Ø¹Ú©Ø³ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯")
        return
    
    try:
        response = openai.Image.create(
            prompt=prompt,
            n=1,
            size="512x512"
        )
        await bot.send_photo(message.chat.id, response['data'][0]['url'])
    except Exception as e:
        await message.reply(f"Ø®Ø·Ø§: {str(e)}")

if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)
